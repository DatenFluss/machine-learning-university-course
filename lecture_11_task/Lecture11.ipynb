{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eb38aa29-fa42-4a70-8cb4-5c3284f5f2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7871\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7871/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import io\n",
    "import requests\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "# Function to download and load the model from GitHub\n",
    "def load_model_from_github():\n",
    "    # Raw file URL from GitHub (change 'blob' to 'raw' in the URL)\n",
    "    model_url = \"https://raw.githubusercontent.com/DatenFluss/machine-learning-university-course/main/res/models/font_recognition_cnn.keras\"\n",
    "    \n",
    "    try:\n",
    "        # Download the model file\n",
    "        response = requests.get(model_url, allow_redirects=True)\n",
    "        if response.status_code == 200:\n",
    "            # Create a temporary file to save the model\n",
    "            with tempfile.NamedTemporaryFile(delete=False, suffix='.keras') as tmp_file:\n",
    "                tmp_file.write(response.content)\n",
    "                tmp_file_path = tmp_file.name\n",
    "            \n",
    "            # Load the model from the temporary file\n",
    "            model = tf.keras.models.load_model(tmp_file_path)\n",
    "            \n",
    "            # Clean up the temporary file\n",
    "            os.unlink(tmp_file_path)\n",
    "            \n",
    "            return model\n",
    "        else:\n",
    "            raise Exception(f\"Failed to download model: Status code {response.status_code}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model from GitHub: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Load the model from GitHub\n",
    "model = load_model_from_github()\n",
    "\n",
    "# Font class names (make sure these match exactly with what the model was trained on)\n",
    "font_classes = [\n",
    "    \"AGENCY\", \"ARIAL\", \"BAITI\", \"BANKGOTHIC\", \"BASKERVILLE\", \"BAUHAUS\", \"BELL\",\n",
    "    \"BERLIN\", \"BERNARD\", \"BITSTREAMVERA\", \"BLACKADDER\", \"BODONI\", \"BOOK\",\n",
    "    \"BOOKMAN\", \"BRADLEY\", \"BRITANNIC\", \"BROADWAY\", \"BRUSH\", \"BUXTON\", \"CAARD\",\n",
    "    \"CALIBRI\", \"CALIFORNIAN\", \"CALISTO\", \"CAMBRIA\", \"CANDARA\", \"CASTELLAR\",\n",
    "    \"CENTAUR\", \"CENTURY\", \"CHILLER\", \"CITYBLUEPRINT\", \"COMIC\",\n",
    "    \"COMMERCIALSCRIPT\", \"COMPLEX\", \"CONSOLAS\", \"CONSTANTIA\", \"COOPER\",\n",
    "    \"COPPERPLATE\", \"CORBEL\", \"COUNTRYBLUEPRINT\", \"COURIER\", \"CREDITCARD\",\n",
    "    \"CURLZ\", \"DUTCH801\", \"E13B\", \"EBRIMA\", \"EDWARDIAN\", \"ELEPHANT\", \"ENGLISH\",\n",
    "    \"ENGRAVERS\", \"ERAS\", \"EUROROMAN\", \"FELIX TITLING\", \"FOOTLIGHT\", \"FORTE\",\n",
    "    \"FRANKLIN\", \"FREESTYLE\", \"FRENCH\", \"GABRIOLA\", \"GADUGI\", \"GARAMOND\",\n",
    "    \"GEORGIA\", \"GIGI\", \"GILL\", \"GLOUCESTER\", \"GOTHICE\", \"GOUDY\", \"GUNPLAY\",\n",
    "    \"HAETTENSCHWEILER\", \"HARLOW\", \"HARRINGTON\", \"HIGH TOWER\", \"HIMALAYA\",\n",
    "    \"IMPACT\", \"IMPRINT\", \"INFORMAL\", \"ISOC\", \"ITALIC\", \"JAVANESE\", \"JOKERMAN\",\n",
    "    \"JUICE\", \"KRISTEN\", \"KUNSTLER\", \"LEELAWADEE\", \"LUCIDA\", \"MAGNETO\",\n",
    "    \"MAIANDRA\", \"MATURA\", \"MINGLIU\", \"MISTRAL\", \"MODERN\", \"MONEY\",\n",
    "    \"MONOSPAC821\", \"MONOTXT\", \"MONOTYPE\", \"MV_BOLI\", \"MYANMAR\", \"NIAGARA\",\n",
    "    \"NINA\", \"NIRMALA\", \"NUMERICS\", \"ONYX\", \"PALACE\", \"PALATINO\", \"PANROMAN\",\n",
    "    \"PAPYRUS\", \"PERPETUA\", \"PHAGSPA\", \"PLAYBILL\", \"PMINGLIU-EXTB\", \"PRISTINA\",\n",
    "    \"PROXY\", \"QUICKTYPE\", \"RAGE\", \"RAVIE\", \"REFERENCE\", \"RICHARD\", \"ROCKWELL\",\n",
    "    \"ROMAN\", \"ROMANTIC\", \"SANSSERIF\", \"SCRIPT\", \"SCRIPTB\", \"SERIF\",\n",
    "    \"SHOWCARD\", \"SIMPLEX\", \"SITKA\", \"SKETCHFLOW\", \"SNAP\", \"STENCIL\", \"STYLUS\",\n",
    "    \"SUPERFRENCH\", \"SWIS721\", \"SYLFAEN\", \"TAHOMA\", \"TAI\", \"TECHNIC\",\n",
    "    \"TEMPUS\", \"TIMES\", \"TREBUCHET\", \"TW\", \"TXT\", \"VERDANA\", \"VIN\", \"VINER\",\n",
    "    \"VINETA\", \"VIVALDI\", \"VLADIMIR\", \"WIDE\", \"YI BAITI\"\n",
    "]\n",
    "\n",
    "\n",
    "def preprocess_image(image):\n",
    "    try:\n",
    "        # Convert to grayscale if image is RGB\n",
    "        if len(np.array(image).shape) == 3:\n",
    "            image = Image.fromarray(np.array(image)).convert('L')\n",
    "        \n",
    "        # Resize to 20x20 pixels\n",
    "        image_resized = image.resize((20, 20), Image.Resampling.LANCZOS)\n",
    "        \n",
    "        # Convert to numpy array and normalize\n",
    "        img_array = np.array(image_resized).astype('float32')\n",
    "        img_array = img_array / 255.0\n",
    "        \n",
    "        # Reshape for model input\n",
    "        img_array = img_array.reshape(1, 20, 20, 1)\n",
    "        \n",
    "        return img_array\n",
    "    except Exception as e:\n",
    "        print(f\"Error in preprocessing: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def predict_font(input_image):\n",
    "    try:\n",
    "        if input_image is None:\n",
    "            return None\n",
    "        \n",
    "        # Preprocess the image\n",
    "        processed_image = preprocess_image(input_image)\n",
    "        if processed_image is None:\n",
    "            return None\n",
    "            \n",
    "        # Make prediction\n",
    "        predictions = model.predict(processed_image, verbose=0)\n",
    "        \n",
    "        # Get top 3 predictions\n",
    "        top_3_indices = np.argsort(predictions[0])[-3:][::-1]\n",
    "        top_3_probabilities = predictions[0][top_3_indices]\n",
    "        \n",
    "        # Create dictionary of results\n",
    "        results = {\n",
    "            font_classes[idx]: float(prob) \n",
    "            for idx, prob in zip(top_3_indices, top_3_probabilities)\n",
    "        }\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in prediction: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Create Gradio interface\n",
    "iface = gr.Interface(\n",
    "    fn=predict_font,\n",
    "    inputs=gr.Image(type=\"pil\"),\n",
    "    outputs=gr.Label(num_top_classes=3),\n",
    "    title=\"Font Recognition\",\n",
    "    description=\"Upload a character image to identify its font. The model will predict the top 3 most likely fonts.\",\n",
    "    examples=[],\n",
    "    cache_examples=False\n",
    ")\n",
    "\n",
    "# Launch the interface\n",
    "if __name__ == \"__main__\":\n",
    "    iface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6fa30c-a8b0-4766-947d-b44635b392d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
